{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Sklearn Guide\n",
    "    Darren Lund\n",
    "    NaiveBayes\n",
    "    Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Take your Naive Bayes classifier from your homework and rewrite it as a class that inherits from `BaseEstimator` and `ClassifierMixin`.\n",
    "Implement `__init__()`, `fit()`, and `predict()` in a way that matches `sklearn` conventions.\n",
    "\n",
    "Test your model on the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Naive_Bayes(BaseEstimator, ClassifierMixin) :\n",
    "    '''\n",
    "    A naive bayesian classifier that inherits from sklearn BaseEstimator\n",
    "    '''\n",
    "    def __init__(self,verbose=False) :\n",
    "        '''\n",
    "        Initialize the Naive_Bayes classifier\n",
    "        '''\n",
    "        self.verbose=verbose\n",
    "    \n",
    "    def fit(self,X,y) :\n",
    "        '''\n",
    "        Fits the data for the classifier\n",
    "        \n",
    "        Inputs :\n",
    "            X (nparray) - Data to fit\n",
    "            y (1d array)\n",
    "        '''\n",
    "        self.classes_ = list(set(y))\n",
    "        self.classes_.sort()\n",
    "        self.mus_ = []\n",
    "        self.sig2s_ = []\n",
    "        self.y_probs_ = []\n",
    "        for i in range(len(self.classes_)) :\n",
    "            self.mus_.append(np.average(X[y==self.classes_[i]],axis=0))\n",
    "            self.sig2s_.append(np.var(X[y==self.classes_[i]],axis=0))\n",
    "            self.y_probs_.append(sum(y == self.classes_[i])/len(y))\n",
    "        return self\n",
    "            \n",
    "    def predict_proba(self,X) :\n",
    "        '''\n",
    "        Predicts the probability of data X for each class\n",
    "        '''\n",
    "        m = X.shape[0]\n",
    "        n = len(self.classes_)\n",
    "        #log_prob_0 = np.log(self.prob_0) + np.sum(-(X-self.mu_0)**2/(2*self.sigma2_0),axis=1) - np.sum(0.5*np.log(2*np.pi*self.sigma2_0))\n",
    "        probs = np.zeros((m,n))\n",
    "        for i in range(n) :\n",
    "            probs[:,i] = np.log(self.y_probs_[i])*np.ones_like(probs[:,i]) + np.sum(-(X-self.mus_[i])**2/(2*self.sig2s_[i]),axis=1) - np.sum(0.5*np.log(2*np.pi*self.sig2s_[i]))\n",
    "        return probs\n",
    "    \n",
    "    def predict(self,X) :\n",
    "        '''\n",
    "        Predicts class labels of data X\n",
    "        '''\n",
    "        probs = self.predict_proba(X)\n",
    "        indices = np.argmax(probs,axis=1)\n",
    "        labels = [self.classes_[indices[i]] for i in range(len(indices))]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "tr_x, ts_x, tr_y, ts_y = train_test_split(iris.data,iris.target)\n",
    "mygnb = Naive_Bayes()\n",
    "mygnb.fit(tr_x,tr_y)\n",
    "mygnb.score(ts_x,ts_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Write a transformer class where the `fit()` and `transform()` methods takes in $X$ as a pandas Data Frame.\n",
    "For each numerical column, replace any `nan` entries with the mean of the column.\n",
    "Drop string columns.\n",
    "Return the data as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformers(BaseEstimator, TransformerMixin) :\n",
    "    '''\n",
    "    Transforms a pandas dataframe with numeric and string values to np.array\n",
    "    Drops string columns and fills nans with column averages.\n",
    "    '''\n",
    "    def __init__(self) :\n",
    "        '''\n",
    "        Initialize transformer\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None) :\n",
    "        '''\n",
    "        Creates needed parameters for transformation\n",
    "        Ignores y\n",
    "        '''\n",
    "        assert isinstance(X,pd.Dataframe)\n",
    "        \n",
    "        self.drop_cols_ = X.columns[X.dtypes == object]\n",
    "        self.mus_ = np.sum(X.fillna(0),axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X) :\n",
    "        '''\n",
    "        Transforms the data\n",
    "        '''\n",
    "        assert isinstance(X,pd.Dataframe)\n",
    "        \n",
    "        X = X.drop(self.drop_cols_)\n",
    "        cols = X.columns\n",
    "        for i in range(len(cols)) :\n",
    "            X[cols[i]].fillna(self.mus_[i])\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Use `cross_validate()` to score your class from Problem 1 on the iris dataset.\n",
    "Do the same for a `LogisticRegressionClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time\t: 0.00148272514343\n",
      "score_time\t: 0.000649988651276\n",
      "test_score\t: 0.953525641026\n",
      "train_score\t: 0.964438122333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate(mygnb, iris.data, iris.target, cv=4)\n",
    "for val in results.keys() :\n",
    "    print(str(val)+'\\t: '+str(np.average(results[val])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time\t: 0.0011699795723\n",
      "score_time\t: 0.000410795211792\n",
      "test_score\t: 0.952457264957\n",
      "train_score\t: 0.962126600284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "results = cross_validate(lgr, iris.data, iris.target, cv=4)\n",
    "for val in results.keys() :\n",
    "    print(str(val)+'\\t: '+str(np.average(results[val])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Take the cancer data set (`datasets.load_breast_cancer()`) and do a grid search on an SVM (`sklearn.linear.svm`) with the parameter `C` as .01, .1, or 1, and the parameter `kernel` as `\"linear\"`, `\"poly\"`, `\"rbf\"`, and `\"sigmoid\"`.\n",
    "\n",
    "What is the best choice of parameters?\n",
    "How well does the corresponding model do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=10000000, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'C': [0.01, 0.1, 1], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "Cs = [0.01,0.1,1]\n",
    "kerns = ['linear','poly','rbf','sigmoid']\n",
    "svc = SVC(max_iter=10000000)\n",
    "clf = GridSearchCV(estimator=svc, param_grid={'C':Cs,'kernel':kerns},n_jobs=4)\n",
    "clf.fit(cancer.data,cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=10000000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.949033391916\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters are $C=1$ with a linear kernel, giving an accuracy of $\\approx 0.94903339$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Make a pipeline of your transformer from Problem 2, a normalizing scaler transformer (`preprocessing.StandardScaler`), a PCA transformer (`decomposition.PCA`), and an SVM classifier (`svm.SVC`).\n",
    "Using the titanic dataset (read in as a pandas DataFrame), do a grid search for the best model, varying your parameters however you see fit.\n",
    "\n",
    "What is your best choice of parameters?\n",
    "How well does the corresponding model do?\n",
    "\n",
    "**Extra credit** to the student with the very best model!\n",
    "To compete, pick your best parameters, do a cross validation with 10 folds, and take the average of the test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
